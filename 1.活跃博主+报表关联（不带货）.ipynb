{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.读取CSV文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "from datetime import timedelta\n",
    "\n",
    "file_path = r'.\\data'\n",
    "\n",
    "#dask处理大型文件，相较于pandas可极大节省时间。\n",
    "#因为表中存在URL链接，因此解码容易出错，忽略。\n",
    "video_data = dd.read_csv(file_path+r'\\video_data.csv',encoding='GB18030',encoding_errors='ignore',\n",
    "usecols=['category', 'author_id','name','title',\n",
    "'rid','comment','likes','share','duration','createtime',\n",
    "'product','sales','volume','aweme_url','collect_count',\n",
    "'download_count','forward_count','play_count','product_count',],\n",
    "dtype={'category':'string','author_id': 'string','name': 'string','title': 'string',\n",
    "'rid': 'string','comment': 'string','likes': 'float32','share':'float32','duration': 'float32',\n",
    "'product': 'string','sales':'float32','volume':'float32','aweme_url':'string','collect_count':'float32',\n",
    "'download_count': 'float32','forward_count': 'float32','play_count':'float32','product_count': 'float32'\n",
    "})\n",
    "\n",
    "print(video_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.选取并保留活跃博主"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_week_begin = pd.Timestamp(\"2023-06-05\")\n",
    "start_week_end = start_week_begin + timedelta(days=7)\n",
    "end_week_begin = pd.Timestamp(\"2024-06-24\")\n",
    "end_week_end = end_week_begin + timedelta(days=7)\n",
    "\n",
    "authors_info = dd.read_csv(file_path+r'\\authors_info.csv',encoding='UTF-8')\n",
    "print(authors_info[\"video_earliest_createtime\"].head())\n",
    "\n",
    "authors_info[\"video_earliest_createtime\"] = dd.to_datetime(\n",
    "    authors_info[\"video_earliest_createtime\"],\n",
    "    format=\"%Y-%m-%d %H:%M:%S\",\n",
    "    errors=\"coerce\")\n",
    "authors_info[\"video_latest_createtime\"] = dd.to_datetime(\n",
    "    authors_info[\"video_latest_createtime\"],\n",
    "    format=\"%Y-%m-%d %H:%M:%S\",\n",
    "    errors=\"coerce\")\n",
    "\n",
    "start_week_mask = (authors_info[\"video_earliest_createtime\"] >= start_week_begin) & \\\n",
    "                  (authors_info[\"video_earliest_createtime\"] <= start_week_end)\n",
    "end_week_mask = (authors_info[\"video_latest_createtime\"] >= end_week_begin) & \\\n",
    "                (authors_info[\"video_latest_createtime\"] <= end_week_end)\n",
    "\n",
    "start_week_authors = authors_info.loc[start_week_mask, \"author_id\"].unique()\n",
    "end_week_authors = authors_info.loc[end_week_mask, \"author_id\"].unique()\n",
    "\n",
    "active_authors = set(start_week_authors) & set(end_week_authors)#得到活跃博主清单\n",
    "\n",
    "print(f\"活跃博主数量: {len(active_authors)}\")\n",
    "print(\"活跃博主ID示例:\", list(active_authors)[:5])\n",
    "\n",
    "active_mask = video_data[\"author_id\"].isin(active_authors)\n",
    "video_data = video_data[active_mask]#筛选活跃博主\n",
    "\n",
    "print(\"活跃博主数据示例:\")\n",
    "print(video_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.以video_data为主表进行数据合并操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_data = video_data[video_data.sales == 0]\n",
    "\n",
    "fan_trend = dd.read_csv(file_path+r'\\fan_trend.csv',encoding='UTF-8')\n",
    "\n",
    "video_data['createtime'] = dd.to_datetime(video_data['createtime'], \n",
    "                                               format='%Y/%m/%d %H:%M', \n",
    "                                                errors='coerce')\n",
    "fan_trend['time_node'] = dd.to_datetime(fan_trend['time_node'], \n",
    "                                              format='%Y-%m-%d %H:%M:%S', \n",
    "                                              errors='coerce')\n",
    "video_data = video_data.assign(\n",
    "    createtime = video_data['createtime'].astype('datetime64[ns]'))\n",
    "fan_trend = fan_trend.assign(\n",
    "    time_node = fan_trend['time_node'].astype('datetime64[ns]'))\n",
    "\n",
    "video_data['date_only'] = dd.to_datetime(video_data['createtime']).dt.date\n",
    "fan_trend['date_only'] = dd.to_datetime(fan_trend['time_node']).dt.date\n",
    "video_data = video_data.assign(\n",
    "    date_only = video_data['date_only'].astype('datetime64[ns]'))#修正日期格式\n",
    "fan_trend = fan_trend.assign(\n",
    "    date_only = fan_trend['date_only'].astype('datetime64[ns]'))#修正日期格式\n",
    "\n",
    "merged_dask1 = video_data.merge(\n",
    "    fan_trend[['cid','date_only','follower_count']],\n",
    "    left_on=['author_id','date_only'],\n",
    "    right_on=['cid', 'date_only'],\n",
    "    how='left'\n",
    ").drop(columns=['cid', 'date_only'])\n",
    "\n",
    "print(merged_dask1.head())\n",
    "\n",
    "merged_dask2 = merged_dask1.merge(\n",
    "    authors_info[['author_id','category']],\n",
    "    left_on=['author_id'],\n",
    "    right_on=['author_id'],\n",
    "    how='left')\n",
    "\n",
    "#删除其他表，大幅释放内存\n",
    "del merged_dask1\n",
    "del video_data\n",
    "del fan_trend\n",
    "\n",
    "print(merged_dask2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.保存文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将多分区整合为单一文件，提高后续阅读效率\n",
    "merged_dask2.to_csv(file_path+'\\without_sales.csv',index=False,single_file=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
